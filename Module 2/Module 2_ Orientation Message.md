# Orientation message

## Module 2: Voice-controlled AI

Hello, and welcome to Module 2 of Advanced Prompt Engineering for Journalists.

This week we focus on voice-controlled AI: speaking to your terminal instead of typing. For many journalists, typing is second nature. But voice input can change how you work with AI tools, especially when you're multitasking, on deadline, or simply thinking out loud.

Voice-to-text technology has improved dramatically in recent years. Free and local transcription options now rival expensive commercial services. This module teaches you to set up voice input for your terminal and use it to interact with AI coding assistants like Claude Code.

### Learning objectives

By the end of this module, you will be able to:

1. Explain the difference between raw transcription mode and agent mode for terminal voice input
2. Set up at least one voice transcription tool on your computer
3. Use voice dictation to give commands to an AI coding assistant
4. Identify when voice input is faster than typing for journalism workflows

### This week's activities

- Watch the video lectures on voice transcription tools and terminal integration
- Complete the readings on voice-to-text for developers
- Try the hands-on exercise: dictating a story outline to Claude Code
- Participate in the discussion forums
- Complete the quiz

The video lectures walk through three transcription options: Gemini Flash (free API, works on any platform), Windows Speech Recognition (built-in, no setup), and Parakeet (local GPU, fully offline). You don't need all three. Pick the one that matches your setup.

Check into the discussion forums this week. Voice input is personal. What works for one person may not work for another. Share your experiences, and learn from your classmates.

Please complete all module activities before the end of the week.

If you have questions about the course content, post in the "Question for the instructor" forum.

See you online.
