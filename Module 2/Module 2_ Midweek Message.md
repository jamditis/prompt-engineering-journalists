# Midweek message

## Module 2: Voice-controlled AI

Hello everyone,

We're halfway through Week 2. By now you should have:

- Watched the video lectures on transcription options
- Started the readings on voice-to-text tools
- Chosen which transcription method to try

### Common questions so far

**"The transcription keeps getting my words wrong."**

This is normal, especially for names, numbers, and jargon. Speak clearly and at a moderate pace. You can also try adding custom vocabulary if your tool supports it. For journalism work, expect to make corrections. Voice input is about speed for the first draft, not perfection.

**"I don't have a GPU for local transcription."**

You don't need one. Windows Speech Recognition and macOS Dictation work without a GPU. Gemini Flash runs in the cloud. Only NVIDIA Parakeet and some Whisper configurations need a GPU.

**"Voice input feels awkward."**

It takes practice. Most people feel strange dictating at first, especially in shared workspaces. Try it at home first. After a few sessions, it becomes more natural.

### This week's focus

If you haven't started the hands-on exercise yet, now is the time. The exercise asks you to dictate a story outline to Claude Code. Give yourself at least 30 minutes to work through it.

The discussion forums are active. Take a look at what your classmates are sharing about their voice input experiences.

See you in the forums.
