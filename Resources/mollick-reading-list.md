# Ethan Mollick reading list

Ethan Mollick is Associate Professor at the Wharton School of the University of Pennsylvania. His Substack, [One Useful Thing](https://www.oneusefulthing.org/), is the most consistently practical writing on working with AI. Several ideas from this course — models / apps / harnesses, cyborg vs. centaur, "you aren't prompting, you are managing" — come directly from his work.

This list is organized thematically. You don't need to read all of these. Browse by topic based on where you are in the course.

---

## Getting started / foundations

**[An Opinionated Guide to Using AI Right Now](https://www.oneusefulthing.org/p/an-opinionated-guide-to-using-ai)**
October 19, 2025 — Which tools to use, which to skip, and why the gap between marketing and actual capability matters. Practical selection criteria for journalists evaluating new tools.

**[Getting started with AI: Good enough prompting](https://www.oneusefulthing.org/p/getting-started-with-ai-good-enough)**
November 24, 2024 — Argues that context matters more than prompt perfection; recommends 10 hours of hands-on practice over studying theory. Directly relevant to understanding why context files (CLAUDE.md, GEMINI.md, AGENTS.md) work.

**[A guide to prompting AI (for what it is worth)](https://www.oneusefulthing.org/p/a-guide-to-prompting-ai-for-what)**
April 16, 2023 — The classic Mollick prompting guide. No magic prompts exist; what works is giving AI context (persona, audience, constraints, examples) and iterating. This is the conceptual foundation for Module 2.

**[15 Times to use AI, and 5 Not to](https://www.oneusefulthing.org/p/15-times-to-use-ai-and-5-not-to)**
December 2024 — AI is most useful for tasks you could do but shouldn't waste time on. Identifies where AI genuinely helps vs. where it undermines judgment or quality. Read before designing any automation.

---

## Working methods: cyborg vs. centaur

**[Captain's log: the irreducible weirdness of prompting AIs](https://www.oneusefulthing.org/p/captains-log-the-irreducible-weirdness)**
March 4, 2024 — Different prompt framings (Star Trek, political thriller, etc.) dramatically change AI accuracy. Context isn't just about facts — it's about establishing a frame for how AI should think. Directly relevant to how you write CLAUDE.md files.

**[Innovation through prompting](https://www.oneusefulthing.org/p/innovation-through-prompting)**
April 22, 2024 — Argues that prompts function as "programs in prose" that non-technical experts can author. The conceptual basis for custom skills: you don't need to write code to encode domain expertise.

**[Management as AI superpower](https://www.oneusefulthing.org/p/management-as-ai-superpower)**
January 27, 2026 — Managing AI agents requires the same skills as managing people: clear instructions, feedback, and evaluation criteria. As development shifts from writing code to directing AI, management skills become the bottleneck.

**[Giving your AI a Job Interview](https://www.oneusefulthing.org/p/giving-your-ai-a-job-interview)**
November 12, 2025 — How to test and customize AI models to find what works for your specific tasks. Useful for evaluating whether a tool fits a particular reporting workflow before committing to it.

---

## Agents and automation

**[Real AI Agents and Real Work](https://www.oneusefulthing.org/p/real-ai-agents-and-real-work)**
September 29, 2025 — AI agents that can plan and use tools to accomplish multi-step tasks are now practical, not theoretical. Small accuracy improvements lead to large gains in what agents can complete. Read before Module 4.

**[On Working with Wizards](https://www.oneusefulthing.org/p/on-working-with-wizards)**
September 11, 2025 — Working with AI systems that produce impressive results but operate in opaque ways. Covers trust, verification, and workflow design — critical for journalism, where you can't just accept output.

**[Three Years from GPT-3 to Gemini 3](https://www.oneusefulthing.org/p/three-years-from-gpt-3-to-gemini)**
November 18, 2025 — Chronicles how fast model capabilities have changed; demonstrates Gemini 3 building complete interactive applications. Useful context for understanding what agent-based workflows can now do.

---

## AI's capabilities and limits

**[On Jagged AGI: o3, Gemini 2.5, and everything after](https://www.oneusefulthing.org/p/on-jagged-agi-o3-gemini-25-and-everything)**
April 2025 — Introduces "Jagged AGI": AI with superhuman ability at narrow tasks but obvious gaps elsewhere. Explains why AI fails in unpredictable ways — and why retrieval systems (RAG) matter: they fill the gaps the model can't fill from memory.

**[Mass Intelligence](https://www.oneusefulthing.org/p/mass-intelligence)**
August 28, 2025 — We're entering an era where powerful AI is as accessible as Google Search. Every institution built for scarce intelligence — schools, hospitals, newsrooms — now has to operate with abundant AI. Raises the stakes for figuring out what human editorial judgment is actually for.

**[GPT-5: It Just Does Stuff](https://www.oneusefulthing.org/p/gpt-5-it-just-does-stuff)**
August 7, 2025 — Newer models automatically select computation depth and handle complex tasks with minimal instruction. Relevant for understanding why describing a workflow in plain English can produce a working pipeline.

---

## Education and learning

**[Post-apocalyptic education](https://www.oneusefulthing.org/p/post-apocalyptic-education)**
August 30, 2024 — Addresses what education looks like when AI can complete most traditional assignments. The parallel to journalism is direct: if AI can generate copy, what is a journalist's editorial judgment actually for?

---

## Book

**Co-Intelligence: Living and Working with AI** (2024)
Penguin Random House — [Publisher page](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)
NYT bestseller; named best book of 2024 by The Economist and Financial Times. Develops the cyborg/centaur framework for human-AI collaboration. The conceptual foundation for everything in this course.

---

## Already assigned in the course

These Mollick pieces appear as required readings in specific modules:

- **["A guide to which AI to use in the agentic era"](https://www.oneusefulthing.org/p/a-guide-to-which-ai-to-use-agentic)** — Introduction module + Module 1 (models / apps / harnesses framework)
- **["Claude Code and What Comes Next"](https://www.oneusefulthing.org/p/claude-code-and-what-comes-next)** — Introduction module (what the harness layer looks like in practice)
